# SIPB Deep Learning Group
The schedule of readings for the SIPB/Cambridge AI Deep Learning Group If you have any papers you'd like to discuss, please either make a pull request, or send an email to the group and we'll add it. Papers with implementations available are strongly preferred.


## Suggested Papers:

* [Improving speech recognition by revising gated recurrent units](https://arxiv.org/abs/1710.00641)
* [A systematic study of the class imbalance problem in convolutional neural network](http://arxiv.org/abs/1710.05381)
* [Designing Neural Network Architectures using Reinforcement Learning](https://arxiv.org/abs/1611.02167) ([Implementation](https://github.com/bowenbaker/metaqnn))
    * Accompanying paper: [Practical Neural Network Performance Prediction for Early Stopping](https://arxiv.org/pdf/1705.10823.pdf)
* [Toward an Integration of Deep Learning and Neuroscience](http://journal.frontiersin.org/article/10.3389/fncom.2016.00094/full) (Potential companion paper to "Neuroscience-inspired AI")
* [Label, Segment, Featurize: a cross domain framework for prediction engineering](http://dai.lids.mit.edu/Pred_eng.pdf)
* [Learning to Infer Graphics Programs from Hand-Drawn Images](https://arxiv.org/abs/1707.09627) and [supplement](http://web.mit.edu/ellisk/www/graphicsProgramSupplement.pdf).
* [Information Dropout: Learning Optimal Representations Through Noisy Computation](https://arxiv.org/pdf/1611.01353.pdf). [(Implementation)](https://github.com/ucla-vision/information-dropout).
* [On the emergence of invariance and disentangling in deep representations](https://arxiv.org/pdf/1706.01350.pdf).
* [Reinforcement Learning with Deep Energy-Based Policies](https://arxiv.org/pdf/1702.08165.pdf). ([Blog](http://bair.berkeley.edu/blog/2017/10/06/soft-q-learning/), [Code](https://github.com/haarnoja/softqlearning), [Videos](https://sites.google.com/view/softqlearning/home))
* [Meta-Learning Shared Hierarchies](https://arxiv.org/pdf/1710.09767.pdf). [Implementation](https://github.com/openai/mlsh)
* [Explaining NonLinear Classification Decisions with Deep Taylor Decomposition](https://arxiv.org/pdf/1512.02479.pdf).
* [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829v2)
* [Opening the black box of Deep Neural Networks via Information](https://arxiv.org/pdf/1703.00810.pdf)
* [Unifying Count-Based Exploration and Intrinsic Motivation](https://arxiv.org/pdf/1606.01868.pdf)
* [Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf)
* [AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks](https://arxiv.org/abs/1711.10485)
* [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/pdf/1506.01497.pdf) ([Implementation](https://github.com/jwyang/faster-rcnn.pytorch))
* [Learning to Optimize Neural Nets](https://arxiv.org/pdf/1703.00441.pdf)

## Schedule:


| Date  | Paper | Implementation |
| ------------- | ------------- |------------- |
| 12.7.16  | [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657)  |
|12.14.16|[Key-Value Memory Networks for Directly Reading Documents](https://arxiv.org/abs/1606.03126)||
|12.21.16|[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/abs/1612.03242/)||
|1.17.17|[Neural Semantic Encoders](https://arxiv.org/abs/1607.04315)||
|1.24.17|[Understanding Deep Learning Requires Rethinking Generalization](https://arxiv.org/abs/1611.03530)||
|1.31.17|[Mastering the Game of Go with Deep Networks](http://airesearch.com/wp-content/uploads/2016/01/deepmind-mastering-go.pdf)||
|2.7.17|[Towards Principled Methods for Training GANs](https://arxiv.org/abs/1701.04862)||
|2.14.17|[Wasserstein GAN](https://arxiv.org/abs/1701.07875)||
|3.7.17|[Neural Programmer Interpreters](https://arxiv.org/abs/1511.06279)||
|3.21.17|[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004)||
|3.28.17|[Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning](https://arxiv.org/abs/1509.08731)||
|4.4.17|[End to End Learning for Self-Driving Cars](https://arxiv.org/abs/1604.07316)||
|4.18.17|[Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906)||
|4.25.17|[Strategic Attentive Writer for Learning Macro-Actions](https://arxiv.org/abs/1606.04695)||
|5.4.17|[Using Fast Weights to Attend to the Recent Past](https://arxiv.org/abs/1610.06258)||
|5.9.17|[Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)|[code](https://github.com/igul222/improved_wgan_training)|
|5.16.17|[Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477)|[modular_rl](https://github.com/joschu/modular_rl)|
|5.23.17|[Emergence of Grounded Compositional Language in Multi-Agent Populations](https://arxiv.org/abs/1703.04908)||
|5.30.17|[High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438)|[modular_rl](https://github.com/joschu/modular_rl)|
|6.6.17|[Artistic style transfer for videos](https://arxiv.org/abs/1604.08610)|[artistic video](https://github.com/manuelruder/artistic-videos)|
|6.13.17|[Lie-Access Neural Turing Machines](https://arxiv.org/abs/1611.02854)|[harvardnlp](https://github.com/harvardnlp/lie-access-memory)|
|6.20.17|[Neural Episodic Control](https://arxiv.org/abs/1703.01988)|[PFCM](https://github.com/PFCM/neural-episodic-control)|
|7.11.17|[Speaker diarization using deep neural network embeddings](http://www.danielpovey.com/files/2017_icassp_diarization_embeddings.pdf)||
|7.18.17|[A simple neural network module for relational reasoning](https://arxiv.org/abs/1706.01427)|[relation-network](https://github.com/Alan-Lee123/relation-network)|
|7.25.17|[Decoupled Neural Interfaces using Synthetic Gradients](https://arxiv.org/abs/1608.05343) & [follow-up](https://arxiv.org/abs/1703.00522)|[dni.pytorch](https://github.com/andrewliao11/dni.pytorch)|
|8.1.17|[Full-Capacity Unitary Recurrent Neural Networks](https://arxiv.org/pdf/1611.00035.pdf)|[complex_RNN](https://github.com/amarshah/complex_RNN), [urnn](https://github.com/stwisdom/urnn)|
|8.8.17|[Hyper Networks](https://arxiv.org/abs/1609.09106)|[otoro blog](http://blog.otoro.net/2016/09/28/hyper-networks/)|
|8.15.17|[Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences](https://arxiv.org/abs/1610.09513)|[plstm](https://github.com/dannyneil/public_plstm)|
|8.22.17|[Designing Neural Network Architectures using Reinforcement Learning](https://arxiv.org/abs/1611.02167)|[metaqnn](https://github.com/bowenbaker/metaqnn)|
|8.29.17|[Deep Transfer Learning with Joint Adaptation Networks](https://arxiv.org/abs/1605.06636)|jmmd.{[cpp](https://github.com/thuml/transfer-caffe/blob/41455ac37f11c18fb19509c93b381bcd51ded68e/src/caffe/layers/jmmd_layer.cpp),[hpp](https://github.com/thuml/transfer-caffe/blob/41455ac37f11c18fb19509c93b381bcd51ded68e/src/caffe/layers/jmmd_layer.cpp)}|
|9.5.17|[Recurrent Dropout Without Memory Loss](https://arxiv.org/abs/1603.05118)|[rnn_cell_mulint_modern.py](https://github.com/NickShahML/tensorflow_with_latest_papers/blob/master/rnn_cell_mulint_modern.py#L141)|
|9.12.17|[Neuroscience-inspired AI](http://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3)||
|9.19.17|[Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400)|[cbfinn](https://github.com/cbfinn)|
|9.26.17|[Variational Boosting: Iteratively Refining Posterior Approximations](https://arxiv.org/abs/1611.06585)|[vboost](https://github.com/andymiller/vboost)|
|10.10.17|[Zero-Shot Learning Through Cross-Modal Transfer](http://papers.nips.cc/paper/5027-zero-shot-learning-through-cross-modal-transfer.pdf)|[zslearning](https://github.com/mganjoo/zslearning)|
|10.17.17|[What does Attention in Neural Machine Translation Pay Attention to?](https://arxiv.org/abs/1710.03348v1)||
|10.24.17|[Poincar√© Embeddings for Learning Hierarchical Representations](https://arxiv.org/abs/1705.08039)|[poincare_embeddings](https://github.com/nishnik/poincare_embeddings)|
|11.7.17|[Meta-Learning with Memory-Augmented Neural Networks](http://proceedings.mlr.press/v48/santoro16.html)|[ntm-meta-learning](https://github.com/ywatanabex/ntm-meta-learning)|
|11.14.17|[Mastering the game of Go without human knowledge](https://deepmind.com/documents/119/agz_unformatted_nature.pdf) ||
|11.28.17|[Emergent Complexity via Multi-Agent Competition](https://arxiv.org/abs/1710.03748) [(blog post)](https://blog.openai.com/competitive-self-play/?)|[multiagent-competition](https://github.com/openai/multiagent-competition)|
|12.5.17|[Stochastic Neural Networks for Hierarchical Reinforcement Learning](https://arxiv.org/abs/1704.03012)|[snn4hrl](https://github.com/florensacc/snn4hrl)|
|12.12.17|[Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks](https://arxiv.org/abs/1607.01426) | [(ChainsofReasoning)](https://rajarshd.github.io/ChainsofReasoning/)
|1.9.18|[Intro to Coq](http://adam.chlipala.net/cpdt/) |
|1.16.18|[Go for a Walk and Arrive at the Answer](https://arxiv.org/abs/1711.05851), [RelNet: End-to-End Modeling of Entities & Relations](https://arxiv.org/abs/1706.07179)|
|1.23.18|[Visualizing The Loss Landscape Of Neural Nets](https://arxiv.org/pdf/1712.09913.pdf)|
|1.30.18|[The Case for Learned Index Structures](https://arxiv.org/abs/1712.01208)|
|2.6.18|[Deep vs. Shallow Networks: An Approximation Theory Perspective](https://arxiv.org/abs/1608.03287)|
|2.13.18|[Nested LSTMs](https://arxiv.org/abs/1801.10308)|[Nested-LSTM](https://github.com/titu1994/Nested-LSTM)|
|2.20.18|[Information Dropout](https://arxiv.org/pdf/1611.01353.pdf)|[InformationDropout](https://github.com/coventry/InformationDropout/blob/master/information_dropout.py), [official implementation](https://github.com/ucla-vision/information-dropout)|
|2.27.18|[AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks](https://arxiv.org/abs/1711.10485)|[StackGAN-v2](https://github.com/hanzhanggit/StackGAN-v2)|
|3.6.18|[Generating Wikipedia by Summarizing Long Sequences](https://arxiv.org/abs/1801.10198)|[wikisum](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum), per [this gist](https://gist.github.com/peterjliu/f0dc9152a630520dc604c783db963aa7)|
